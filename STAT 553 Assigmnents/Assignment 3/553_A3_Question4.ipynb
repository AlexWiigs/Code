{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4  \n",
    "  \n",
    "A random smaple $\\textbf{x}_1, ..., \\textbf{x}_n$ is selected from $N_p(\\mu, \\sigma^2 \\textbf{I})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Derive the MLE $\\hat \\mu$ and the MLE $\\hat \\sigma^2$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood funtion of a multivariate normal distribution is:\n",
    "\n",
    "$$L(\\mu, \\Sigma ; \\textbf{x}_1,..., \\textbf{x}_n) = \\prod_{i=1}^n((\\sqrt{2 \\pi})^p | \\Sigma|^{1/2} )^{-1} \\exp(-\\frac{1}{2}(\\textbf{x}_i - \\mu)' \\Sigma^{-1}(\\textbf{[x}_i- \\mu))$$\n",
    "\n",
    "$$= ((2\\pi)^{np/2}|\\Sigma|^{n/2})^{-1} \\exp(- \\frac{1}{2}\\sum_{i=1}^n(\\textbf{x}_i - \\mu)'\\Sigma^{-1}(\\textbf{x}_i - \\mu))$$  \n",
    "  \n",
    "which gives log likelihood:\n",
    "\n",
    "$$ \\ell = -\\frac{np}{2}\\ln 2 \\pi - \\frac{n}{2}|\\Sigma| - \\frac{1}{2}\\sum_{i=1}^n(\\textbf{x}_i - \\mu)'\\Sigma^{-1}(\\textbf{x}_i - \\mu)$$\n",
    "\n",
    "Substituting in $\\Sigma = I\\sigma^2$ and $|\\Sigma| = (\\sigma^2)^p$ we get:\n",
    "\n",
    "$$\\ell = -\\frac{np}{2}\\ln2\\pi - \\frac{np}{2}\\ln \\sigma^2 - \\frac{\\sum_{i=1}^n(\\textbf{x}_i - \\mu)'(\\textbf{x}_i- \\mu)}{(2\\sigma^2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the MLE esitmate of $\\sigma^2$, take the partial derivateive of $\\ell$ w.r.t. $\\sigma^2$, set it equal to 0 and solve:\n",
    "\n",
    "$$\\frac{\\partial \\ell}{\\partial \\sigma^2} = - \\frac{np}{2 \\sigma^2} + \\frac{\\sum_{i=1}^n(\\textbf{x}_i - \\mu)'(\\textbf{x}_i - \\mu)}{2(\\sigma^2)^2}=0$$\n",
    "\n",
    "$$\\implies \\hat \\sigma^2 = \\frac{\\sum_{i=1}^n (\\textbf{x}_i -\\hat\\mu)' ( \\textbf{x}_i - \\hat\\mu) }{np}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the MLE esitmate of $\\mu$, the same method that was used in Chapter 4 of Methods of Multivariate Analysis for the general case will apply here. We have:\n",
    "\n",
    "$$L = ( (2 \\pi )^{np/2} (\\sigma^2)^{np/2})^{-1} \\exp( - \\frac{1}{2} (\\textbf{x}_i- \\mu)' (\\textbf{x}_i - \\mu))$$\n",
    "\n",
    "$$ = ( (2 \\pi )^{np/2} (\\sigma^2)^{np/2})^{-1} \\exp(- \\frac{1}{2} \\sum_{i=1}^n (\\textbf{x}_i - \\bar{\\textbf{x}} + \\bar{\\textbf{x}} - \\mu)'(\\textbf{x}_i - \\bar{\\textbf{x}} + \\bar{\\textbf{x}} - \\mu))$$\n",
    "\n",
    "$$ = ( (2 \\pi )^{np/2} (\\sigma^2)^{np/2})^{-1} \\exp(- \\frac{1}{2} \\sum_{i=1}^n (\\textbf{x}_i - \\bar{\\textbf{x}})'(\\textbf{x}_i - \\bar{\\textbf{x}}) +  (\\textbf{x}_i - \\bar{\\textbf{x}})'(\\bar{\\textbf{x}} - \\mu) + (\\bar{\\textbf{x}} - \\mu)'(\\textbf{x}_i - \\bar{\\textbf{x}}) + (\\bar{\\textbf{x}} - \\mu)'(\\bar{\\textbf{x}} - \\mu))$$\n",
    "\n",
    "$$ = ( (2 \\pi )^{np/2} (\\sigma^2)^{np/2})^{-1} \\exp(- \\frac{1}{2} \\sum_{i=1}^n (\\textbf{x}_i - \\bar{\\textbf{x}})'(\\textbf{x}_i - \\bar{\\textbf{x}}) + (\\bar{\\textbf{x}} - \\mu)'(\\bar{\\textbf{x}} - \\mu))$$\n",
    "\n",
    "$$= ( (2 \\pi )^{np/2} (\\sigma^2)^{np/2})^{-1})\\exp( (-\\sum_{i=1}^n (\\textbf{x}_i - \\bar{\\textbf{x}})'(\\textbf{x}_i - \\bar{\\textbf{x}}) / 2) - \\frac{n}{2} (\\bar{\\textbf{x}} - \\mu)'(\\bar{\\textbf{x}} - \\mu) )$$\n",
    "\n",
    "We have $-\\frac{n}{2}(\\bar{\\textbf{x}} - \\mu)'(\\bar{\\textbf{x}} - \\mu) \\leq 0$ and $0 < \\exp(-\\frac{n}{2}(\\bar{\\textbf{x}} - \\mu)'(\\bar{\\textbf{x}} - \\mu)) \\leq 1$, with the maximum occurring when the exponent is 0. Therefore, $L$ is maximized when $\\hat \\mu = \\bar{\\textbf{x}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Find $E(\\hat \\mu)$ and $E( \\hat \\sigma^2)$. Are they unbiased estimators?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E(\\hat \\mu) = E(\\bar{\\textbf{x}}) = E( \\sum_{i=1}^n \\textbf{x}_i / n) = \\frac{1}{n} E(\\textbf{x}_1+ \\textbf{x}_2+...+ \\textbf{x}_n) = \\frac{n}{n} \\mu = \\mu$$\n",
    "The MLE estimator for $\\mu$ is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E( \\hat \\sigma^2) = E( \\sum_{i=1}^n \\frac{1}{np} ( \\textbf{x}_i - \\bar{ \\textbf{x} } )'( \\textbf{x}_i - \\bar{ \\textbf{x} }) )$$\n",
    "\n",
    "$$ = \\frac{1}{np} E( \\sum_{i=1}^n \\textbf{x}_i' \\textbf{x}_i - n \\bar{\\textbf{x}}' \\bar{\\textbf{x}} )$$\n",
    "\n",
    "$$ = \\frac{1}{np} (E( \\sum_{i=1}^n  tr(\\textbf{x}_i \\textbf{x}_i' )) - n E( tr(\\bar{\\textbf{x}} \\bar{\\textbf{x}}' )))$$\n",
    "\n",
    "$$ = \\frac{1}{np} (tr( E( \\sum_{i=1}^n \\textbf{x}_i \\textbf{x}_i' )) - n tr (E( \\bar{\\textbf{x}} \\bar{\\textbf{x}}')))$$\n",
    "\n",
    "$$ = \\frac{1}{np} (tr( n( \\Sigma + \\mu \\mu')) - n tr(\\Sigma/n + \\mu \\mu')) = \\frac{1}{np} (n tr(\\Sigma) + n tr(\\mu \\mu') - n tr(\\Sigma /n) - n tr(\\mu \\mu')) $$\n",
    "\n",
    "$$ = \\frac{1}{np}( np \\sigma^2 - p \\sigma^2) = \\frac{1}{np} p \\sigma^2 (n-1) =\\frac{\\sigma^2 p (n-1)}{np} = \\frac{(n-1)}{n}\\sigma^2$$\n",
    "\n",
    "... The MLE estimator $\\hat \\sigma ^2$ is biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
